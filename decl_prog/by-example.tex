\chapter{Declarative semantics by example}
\label{sec:by-example}

\section{First examples}
\label{sec:first-examples}

Consider the code in Figure~\ref{fig:len-app}
that defines versions of length and append
that are specialized to operate on lists
whose elements belong to a very simple type
that has only two values: \verb#a# and \verb#b#.

\begin{figure}[htb]
\begin{verbatim}
:- type e
    --->    a
    ;       b.

:- func len(list(e)) = int.

len([]) = 0.
len([_ | Xs]) = 1 + len(Xs).

:- pred app(list(e), list(e), list(e)).
:- mode app(in, in, out) is det.

app([], Bs, Bs).
app([A | As], Bs, [C | Cs]) :-
    app(As, Bs, Cs).
\end{verbatim}
\caption{Specialized versions of length and append.\label{fig:len-app}}
\end{figure}

Figure~\ref{fig:len-interp} gives a picture
of the declarative semantics of \sym{len/1}.
This semantics consists of a table of \emph{atoms},
which in this case is short for \emph{atomic propositions}.
(This is one of several uses of the word ``atom'' in logic programming;
there are others as well.)
For a function of arity $n$, each atom in the table
consists of the function name applied to $n + 1$ terms,
where the last, distinguished term is the function result.
(For a predicate of arity $n$, each atom in the table
consists of the predicate name applied to $n$ terms,
none of the terms being distinguished.)
% each of which is an \emph{instance}
% of the head of one (or more) of the clauses of the function,
% mapping each possible argument value of the \sym{len/1} function
% to the corresponding result.
These atoms must be \emph{ground},
which means that they may not contain any variables.
The table is infinite,
but like the multiplication table---which is also infinite---%
it is relatively easy to get a picture of what is going on
by looking at (or thinking about) only a finite part of it.

\begin{figure}[htb]
\begin{minipage}{0.5\textwidth}
\begin{verbatim}
len([]) = 0
len([a]) = 1
len([b]) = 1
len([a, a]) = 2
len([a, b]) = 2
len([b, a]) = 2
len([b, b]) = 2
\end{verbatim}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{verbatim}
len([a, a, a]) = 3
len([a, a, b]) = 3
len([a, b, a]) = 3
len([a, b, b]) = 3
len([b, a, a]) = 3
len([b, a, b]) = 3
...
\end{verbatim}
\end{minipage}
\caption{Interpretation of \sym{len/1}.
\label{fig:len-interp}}
\end{figure}

Similarly, Figure~\ref{fig:app-interp} gives a picture
of the declarative semantics of \sym{app/3}.
It again also consists of a table of ground instances
of the head of the \sym{app/3} predicate,
although in this case,
since \sym{app/3} is a predicate,
no argument is distinguished as the return value.
Instead, the arguments must satisfy the relation that holds
between the two input lists
and the output list that results from appending them.

\begin{figure}[htb]
\begin{minipage}{0.5\textwidth}
\begin{verbatim}
app([], [], [])
app([], [a], [a])
app([a], [], [a])
app([], [b], [b])
app([b], [], [b])
app([], [a, a], [a, a])
app([a], [a], [a, a])
app([a, a], [], [a, a])
\end{verbatim}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{verbatim}
app([], [a, b], [a, b])
app([a], [b], [a, b])
app([a, b], [], [a, b])
app([], [b, a], [b, a])
app([b], [a], [b, a])
app([b, a], [], [b, a])
app([], [b, b], [b, b])
...
\end{verbatim}
\end{minipage}
\caption{Interpretation of \sym{app/3}.
\label{fig:app-interp}}
\end{figure}

Tables like these are known as
\emph{Herbrand interpretations\label{gi:herbrand-interpretation}}
(named after Jacques Herbrand,
a French mathematician of the early 20th century).
They assign a meaning to each predicate or function
using a mapping from ground atoms to truth values:
if a ground atom is in the table, then it is true;
if it is not in the table, then it is false.
For example,
if we interpret the function symbol `\verb#+#' as integer addition,
then the table will contain entries such as
\verb#1 + 1 = 2#.
On the other hand,
if we interpret it as string concatenation,
then the table will contain entries such as
\verb#"1" + "1" = "11"#.

Herbrand interpretations are purely syntactic in nature.
This reflects the compiler's view of the program:
the compiler does not know that \sym{len/1}
is supposed to mean ``list length'',
it only knows it as a symbol.
These interpretations also reveal an important fact:
the declarative semantics of a program
can be understood in its entirety
by considering only the truth values taken by ground atoms.
That is, there is no need to consider terms that include
variables from the program.

Furthermore,
this way of thinking works not just for tiny predicates
like \sym{len/1} and \sym{app/3},
but also for much larger pieces of code,
with far more complexity in their intended interpretations.
This ability to \emph{scale} is crucial for
extending our methodology to real-world programs.


\section{Intended interpretations}
\label{sec:intended-interp}

An interpretation\label{gi:interpretation}, generally,
is something that allows the programmer
to comprehend the meaning of terms,
and to determine the truth of ground atoms,
with reasonable ease.
Essentially, it is a specification.
If an interpretation reflects what the programmer intends to implement,
it is called the
\emph{intended interpretation\label{gi:intended-interpretation}}.

To a programmer, even an informal definition can be sufficient.
For example, we could give the intended interpretations
of \sym{len/1} and \sym{app/1} as follows:
\[
\text{for } n \geqslant 0, \ct{len}([x_1, \ldots, x_n]) = n
\]
\[
\text{for } 0 \leqslant m \leqslant n,
\ct{app}([x_1, \ldots, x_m], [x_{m+1}, \ldots, x_n], [x_1, \ldots, x_n])
\]
From these formulas,
it should be clear whether a particular ground atom
is true or false in these interpretations,
even though the interpretations are infinite in size.
The truth value of goals more generally
can be determined by combining the truth values of atomic goals
according to the truth tables of classical logic.

It is the usual practice in Mercury
to describe the intended interpretation
(along with any other pertinent information)
in comments immediately preceding
a \co{pred} or \co{func} declaration.
For example,
in the list module of the Mercury standard library,
the declarations for the \sym{length/1} function
and the \sym{length/2} predicate
appear as follows:
\begin{verbatim}
        % length(List) = Length:
        % length(List, Length):
        %
        % True iff Length is the length of List, i.e. if
        % List contains Length elements.
        %
    :- func length(list(T)) = int.
    :- pred length(list(_T), int).
\end{verbatim}
(The word ``iff'' is the usual abbreviation used in mathematics
for ``if and only if''.)
Similarly, \sym{append/3} is described as follows:
\begin{verbatim}
        % Standard append predicate:
        % append(Start, End, List) is true iff
        % List is the result of concatenating Start and End.
        %
    :- pred append(list(T), list(T), list(T)).
\end{verbatim}
It should be easy to see that
these are equivalent to the intended interpretations we gave above.

It is a good idea to provide comments
that describe the intended interpretation
of any function or predicate
declared in the interface of a module.
Doing this enables users of the module
to understand whether or not they are
using the interface correctly.

We saw above that a list such as \co{[1,2,3]}
can be given the intended interpretation $[1, 2, 3]$.
This might seem trivial,
but it is worth noting that
the former is meant to represent a piece of Mercury syntax,
while the latter is meant to be the kind of notation
that might be seen in a semi-formal mathematical proof.
In this semi-formal notation, it is reasonable to use ellipses and subscripts,
or other ad hoc notation,
to describe the list structures.

A basic example for lists is the ``cons'' function,
which takes an element and a list,
and returns a new list with the element prepended.
Since we do not need to know anything about the element
we can just call it $x$,
and we can assume the list takes the form $[t_1, \ldots, t_n]$,
for some $n \geqslant 0$, and arbitrary elements $t_i$.
We can therefore say that
the intended interpretation of cons is a function that,
given element $x$ and list $[t_1, \ldots, t_n]$,
returns the list $[x, t_1, \ldots, t_n]$.

We have already given intended interpretations
for the list append predicate,
and for the list length function.
The list append function can be specified as:
\[
    \ct{append}([s_1, \ldots, s_m], [t_1, \ldots, t_n]) =
        [s_1, \ldots, s_m, t_1, \ldots, t_n]
\]
% XXX Don't specify the function version of append here.
% We currently use it in a bit, but if we want to do that
% it should be defined where it's needed. Maybe not use it at all?
Similarly, the list reverse function can be specified as:
\[
    \ct{reverse}([t_1, \ldots, t_n]) = [t_n, \ldots, t_1]
\]
We will use these interpretations next
when we implement the queue ADT.


\section{Running example: queue ADT}
\label{sec:queue-spec}

In this section we give the intended interpretation for
a (double-ended) queue abstract data type (\emph{ADT}).
We will use this as a running example
in the remainder of this guide.

The ADT includes abstract operations to initialize a queue,
put elements at the back and get them from the front,
unput elements from the back and unget them at the front,
test two queues for equality,
and convert the queue to an ordinary list.
A queue can be interpreted as a finite sequence of elements,
using the same semi-formal mathematical notation as for lists.

The initialization function, \sym{init/0},
is easy to specify because it just returns
(a representation of)
the empty queue:
\[ \ct{init} = [] \]
Putting an element at the end of the queue
is done with the \sym{put/3} predicate,
which takes as arguments an element,
the queue prior to putting the element at the end,
and the queue after this has been done:
\[ \ct{put}(z, [t_1, \ldots, t_n], [t_1, \ldots, t_n, z]) \]
Getting an element from the front of the queue is done with
a \sym{get/3} predicate,
which is similar except that the second argument
is the queue prior to getting the element from the front:
\[ \ct{get}(z, [z, t_1, \ldots, t_n], [t_1, \ldots, t_n]) \]
The inverse operations,
\sym{unput/3} and \sym{unget/3},
are the same as the forward operations
except that the second and third arguments are reversed:
\begin{IEEEeqnarray*}{c}
    \ct{unput}(z, [t_1, \ldots, t_n, z], [t_1, \ldots, t_n]) \\
    \ct{unget}(z, [t_1, \ldots, t_n], [z, t_1, \ldots, t_n])
\end{IEEEeqnarray*}
Finally,
both the predicate \sym{eq/2}
that tests if two queues contain the same sequence of elements,
and the function \sym{list/1}
that converts a queue to an ordinary list,
are trivial to specify:
\begin{IEEEeqnarray*}{c}
    \ct{eq}([t_1, \ldots, t_n], [t_1, \ldots, t_n]) \\
    \ct{list}([t_1, \ldots, t_n]) = [t_1, \ldots, t_n]
\end{IEEEeqnarray*}
That is,
the intended interpretation of \sym{eq/2}
is the identity relation,
and the intended interpretation of \sym{list/1}
is the identity function.

When implementing queues according to this specification,
the queue type may be defined differently to the list type,
though they are both interpreted as sequences of elements.
If indeed they are different,
the implementation of \sym{list/1}
will not be trivial like the above specification,
but will have to convert between the two representations.
Similarly,
if the representation is not \emph{canonical},
meaning that the same queue may be represented in different ways,
then the implementation of \sym{eq/2}
will not be trivial.


\section{Purity}
\label{sec:purity}

\subsection{Types, modes, and purity}
\label{sec:types-modes-purity}

The code we have seen so far is considered \emph{pure}.
Code that is written using
all but a few Mercury constructs
is automatically pure---%
most Mercury code is pure
without the programmer needing to think about it.
We give the following definition
of what exactly we mean by purity.

\begin{definition}[Purity] \label{gi:pure}
A predicate or function is \emph{pure}
if there exists a declarative interpretation describing its behaviour,
that consistently applies in all circumstances.
\end{definition}

\noindent
In other words,
if for a given function or predicate,
we can picture in our minds a Herbrand interpretation
that characterizes the outcome of all possible calls,
then that predicate or function is pure.

In the last section we gave
the \co{pred} declaration for \sym{append/3}
as it appears in the list module of the standard library.
Figure~\ref{fig:append-decls} gives this \co{pred} declaration again,
along with all of the declared modes.

\begin{figure}
\begin{verbatim}
    :- pred append(list(T), list(T), list(T)).
    :- mode append(di, di, uo) is det.
    :- mode append(in, in, out) is det.
    :- mode append(in, in, in) is semidet.    % implied
    :- mode append(in, out, in) is semidet.
    :- mode append(out, out, in) is multi.
\end{verbatim}
\caption{
Declarations for \sym{append/3}
in the list module of the standard library.
\label{fig:append-decls}}
\end{figure}

The role of the \co{pred} declaration,
which supplies the argument types,
should be clear as regards the interpretations we have seen so far:
a ground atom that is true in the interpretation
will have arguments that are correctly typed.
(If the types of the arguments include one or more type variables,
then the arguments in the interpretation
will have arguments that are correctly typed
for some assignment of values---concrete types---to the type variables.)
The compiler is able to check that this is the case.

The role of the \co{mode} declarations
is perhaps not so clear in the declarative semantics,
but in conjunction with the determinism
each one constrains the set of ground atoms that are true,
for the predicate or function as a whole.
Importantly,
and in line with our definition above,
the same interpretation applies to \emph{all} of the modes.
In Mercury, a predicate or function is pure
only if it has a consistent interpretation across all calls,
regardless of the mode in which the call is made.

This means, for example,
that if a call to $\ct{append}([1],[2,3],z)$
yields a solution $z = [1,2,3]$,
which it does,
then a call to $\ct{append}(x,y,[1,2,3])$
should at some stage yield the solution $x = [1], y = [2,3]$,
which it also does.
Both solutions derive from the fact that
$\ct{append}([1],[2,3],[1,2,3])$ is true
in the declarative interpretation.
The same applies for any other pair of calls
to different modes of \sym{append/3}.

It should not be surprising that this is the case.
The declarative semantics determines
which solutions will be produced,
and it in turn is determined by
the clauses that define a predicate or function.
Since the same clauses apply to all modes,
no discrepancy can arise.


\subsection{Running example: queue declarations}
\label{sec:queue-decl}

Continuing with our queue example,
we can work out from our intended interpretation of the queue operations,
as well as from our intended way of calling them,
what the types, modes, and determinism of each operation will be.
For reference,
the intended interpretations are collected together
in Figure~\ref{fig:queue-spec}.

\begin{figure}
\begin{IEEEeqnarray*}{l}
    \ct{init} = [] \\
    \ct{put}(z, [t_1, \ldots, t_n], [t_1, \ldots, t_n, z]) \\
    \ct{get}(z, [z, t_1, \ldots, t_n], [t_1, \ldots, t_n]) \\
    \ct{unput}(z, [t_1, \ldots, t_n, z], [t_1, \ldots, t_n]) \\
    \ct{unget}(z, [t_1, \ldots, t_n], [z, t_1, \ldots, t_n]) \\
    \ct{eq}([t_1, \ldots, t_n], [t_1, \ldots, t_n]) \\
    \ct{list}([t_1, \ldots, t_n]) = [t_1, \ldots, t_n]
\end{IEEEeqnarray*}
\caption{Intended interpretations for the queue operations
\label{fig:queue-spec}}
\end{figure}

Three types are used in the queue interface:
the type of elements, the type of queues, and the type of lists.
Since the behaviour of queues
does not depend on the specific element values,
we should be able to use elements of any type.
Since we intend to treat all elements in the queue the same way,
we require that all of the elements in a queue are the same type,
and the same is true for the lists we produce
(for which we will use the standard \sym{list/1} type).

We represent the type of elements with a \emph{type variable}
in the predicate/function declarations of the queue operations.
Any actual calls to these predicates and functions
will operate on elements of a specific concrete type,
such as \sym{int} or \sym{string}.
You can think of this as
having the value of the type variable
bound to the actual concrete type of the elements,
for the duration of each call,
just as e.g. the variable representing the first input argument
is bound to the value being passed in that argument position in the call
for the same duration.

Most Mercury code uses \co{T}, the initial letter of \emph{type},
as the default name of type variables
in type, predicate and function declarations
that include only one type variable,
and it is reasonably obvious what entity's type the variable stands for.
(When a type, predicate or function declaration
includes more than one type variable,
or the role of the type variabl is not expected to be immediately clear,
Mercury programmers tend to give the type variable(s) more meaningful names.)

Therefore the abstract type definition for queues
will look like this:
\begin{verbatim}
    :- type queue(T).
\end{verbatim}
% The lists will be of type \co{list(T)}.
% XXX But the list/1 type constructor does not need to be declared by users.

The \sym{init/0} function has no arguments,
and always returns the same queue every time it is called.
So the return value has mode \co{out},
and the function has determinism \co{det}.
These are the default mode and default determinism for functions,
so the declaration is:
\begin{verbatim}
    :- func init = queue(T).
\end{verbatim}

The four main operations have three arguments,
the first being an element and the second and third being queues,
with the elements in all three arguments being of the same type.
Their \co{pred} declarations are therefore
\begin{verbatim}
    :- pred put(T, queue(T), queue(T)).
    :- pred get(T, queue(T), queue(T)).
    :- pred unput(T, queue(T), queue(T)).
    :- pred unget(T, queue(T), queue(T)).
\end{verbatim}
For some of these operations the first argument is an input,
and for others it is an output.
The second and third arguments
form an `\co{in}, \co{out}' pair---%
this is a useful pattern to follow
since it allows for the convenient use of state variables.
We intend the main operations to produce at most one result,
even though there may be
multiple representations of the same output value,
so the determinism of each operation
should be either \co{det} or \co{semidet},
depending on whether or not it always produces a solution.

For both the \sym{put/3} and \sym{unget/3} operations,
the length of the output queue is one greater than
the length of the input queue.
There is no upper limit on the length of queues
so these operations always have a solution,
thus their determinism is \co{det}.
For the \sym{get/3} and \sym{unput/3} operations,
on the other hand,
the length of the output queue is one \emph{less} than
the length of the input queue,
which means there are no solutions if the input queue is empty.
These operations must therefore be \co{semidet},
which leaves us with the following mode declarations:
\begin{verbatim}
    :- mode put(in, in, out) is det.
    :- mode get(out, in, out) is semidet.
    :- mode unput(out, in, out) is semidet.
    :- mode unget(in, in, out) is det.
\end{verbatim}

The \sym{eq/2} predicate takes two queues and either succeeds or fails.
It has no outputs,
so it cannot produce multiple solutions
and its determinism is therefore \co{semidet}.
It is declared as follows:
\begin{verbatim}
    :- pred eq(queue(T), queue(T)).
    :- mode eq(in, in) is semidet.
\end{verbatim}

Normally, programmers put the mode declaration(s) for a predicate or function
immediately after the predicate or function declaration itself,
as in this case.
We separated the predicate declarations of
\sym{put/3}, \sym{get/3}, \sym{unput/3} and \sym{unget/3} above
from their mode declarations
only to improve the flow of their explanations.

It is not an issue for these operations,
but for predicates and functions with many arguments,
programmers may find it hard to visually match up
the mode of each argument with its type.
This is why,
in the usual case that a predicate or function has only one mode declaration,
programmers tend to combine that mode declaration
with the predicate or function declaration:

\begin{verbatim}
    :- pred eq(queue(T)::in, queue(T)::in) is semidet.
\end{verbatim}

We call this combination a \emph{predmode} declaration,
because in most cases, it is applied to predicates.
For functions, there is usually no need for this combination,
because most functions have
the default argument modes and the default determinism,
which do not need to be explicitly declared at all.

The last queue operation, the \sym{list/1} function,
takes a queue and returns a list,
and like \sym{init/0} it uses the default function mode:
\begin{verbatim}
    :- func list(queue(T)) = list(T).
\end{verbatim}

\noindent
The overall set of declarations for the queue operations is therefore

% XXX this overflows; maybe we can shrink the font size for verbatim?
\begin{verbatim}
    :- func init = queue(T).
    :- pred put(T::in, queue(T)::in, queue(T)::out) is det.
    :- pred get(T::out, queue(T)::in, queue(T)::out) is semidet.
    :- pred unput(T::out, queue(T)::in, queue(T)::out) is semidet.
    :- pred unget(T::in, queue(T)::in, queue(T)::out) is det.
    :- pred eq(queue(T)::in, queue(T)::in) is semidet.
    :- func list(queue(T)) = list(T).
\end{verbatim}


\subsection{Mode-dependent clauses}
\label{sec:mode-dependent}

It can be useful to define
multi-moded predicates such as \sym{append/3},
the use of which can readily enable
larger multi-moded predicates to be implemented.
However,
it can sometimes be the case that,
irrespective of how the clauses defining a predicate are written,
making one mode efficient inevitably results in
another mode being inefficient.
An example of this is the following mode of \sym{append/3},
which is commented out in the standard library.
\begin{verbatim}
    % :- mode append(out, in, in) is semidet.
\end{verbatim}
The explanation for why it is commented out says that the mode
``is \co{semidet} in the sense that it does not
succeed more than once---but operationally, it does create a choice-point,
which means both that it is inefficient,
and that the compiler can't deduce that it is \co{semidet}.
Use \co{remove\_suffix} instead.''

If such a mode is nonetheless required for a predicate,
and the inefficiency would otherwise be unacceptable,
then one solution is to implement the predicate
using mode-dependent clauses,
also known as ``different clauses for different modes''.
Doing this, however,
would invalidate our claim from the previous section
that the declarative semantics is consistent across modes,
since the meaning is no longer determined from a single set of clauses.
If the clauses for different modes express different relations,
then a consistent declarative semantics cannot exist.

So this is an issue of purity.
Having a consistent declarative semantics is required,
yet there is no way for the compiler to verify, in general,
that two different sets of clauses express the same relation.
As such,
the compiler will treat a predicate
defined using mode-dependent clauses as impure,
unless the programmer is prepared to promise otherwise.

In the Prolog literature, impure predicates---%
those that do not have a consistent declarative semantics---%
are typically referred to as ``non-logical\label{gi:non-logical}''.
(Note that in Section~\ref{sec:syntax},
we will see this term used in a different sense.)
The canonical example of a non-logical predicate in Prolog
is \co{var/1},
which succeeds if and only if the argument is not bound.
This can be implemented in Mercury as follows.
\begin{verbatim}
    :- impure pred var(T).
    :- mode var(in) is failure.
    :- mode var(unused) is det.

    var(_::in) :- false.
    var(_::unused) :- true.
\end{verbatim}
A call to \co{var(X)} would succeed if,
at the point of call,
\co{X} was not bound to anything.
This implies that the predicate is interpreted as true
for \emph{every} possible argument value.
If the same call was made with \co{X} bound to \co{a},
however, then the call would fail.
This implies that the predicate is interpreted as false
for the value $a$,
which contradicts the previous implication.
Thus it can be seen that the predicate is not pure
according to our definition,
since there does not exist a declarative interpretation
that applies to all modes.


\subsection{Case study: \co{string.append/3}}
\label{sec:purity-example}

In this section we give an example
of using the declarative semantics to resolve a problem
related to the modes of a predicate.
The problem arose in the course of developing the Mercury standard library,
and involved the \sym{append/3} predicate in the string module.

In early versions of the Mercury,
strings were defined as NUL terminated sequences of ASCII characters.
% XXX should this be saying ISO-8859-1?
As with lists,
the string \sym{append/3} predicate had
a ``forward'' mode that appended strings,
as well as a ``reverse'' mode that split them apart.
A consistent declarative semantics applied to both of these modes,
since appending and splitting these strings
were inverse operations.

When we switched to Unicode,
using the UTF-8 representation when generating C code,
a new situation arose.
UTF-8 strings consist of a sequence of fixed-size code units,
which are grouped together into code points
that each contain a varying number of code units.
It is possible for sequences of code units to be ill-formed,
in particular if strings can be split between arbitrary code units.

In the forward (\co{in}, \co{in}, \co{out}) mode
of the Unicode version of string \sym{append/3},
the behaviour is to append the sequences of code units representing
the (possibly ill-formed) input strings.
Consider two strings $s_1$ and $s_2$,
neither of which is well-formed,
but which, when appended together, result in a string,
call it $s_3$, which \emph{is} well-formed.

Given that the forward mode of string \sym{append/3},
when given $s_1$ and $s_2$ as the first two arguments,
will return $s_3$ as the third argument,
its intended interpretation
must include ground atoms such as $\ct{append}(s_1, s_2, s_3)$.

If we want the reverse (\co{out}, \co{out}, \co{in}) mode
of string \sym{append/3}
to have the same semantics as the forward mode, and we do,
then the reverse mode of the predicate
\emph{must} return the pair $s_1$ and $s_2$ as one the solutions
when given as input $s_3$ in the third argument position.
This means that the reverse mode of string \sym{append/3}
must split its input string
at all positions between \emph{code units},
including those in the \emph{middle} of a code point,
even though most callers of the predicate in this mode
would expect that it would split the string only between \emph{code points},
at least if the input string is well formed.

This means that we had to choose one of the following courses of action.
\begin{itemize}
\item
We can make the (\co{out},\co{out},\co{in}) mode
of string \sym{append/3}
break strings between code points,
which conforms to programmer expectations,
but gives the reverse mode a different interpretation,
i.e.\ a different semantics, than the forward mode.
\item
We can make the (\co{out},\co{out},\co{in}) mode
of string \sym{append/3}
break strings between code unit,
which keeps the semantics the same between modes
but breaks programmer expectations,
and does so in a way that is likely to create bugs
(by creating two ill-formed strings out of a well-formed input string).
\item
We can delete the (\co{out},\co{out},\co{in}) mode
of string \sym{append/3}.
This does not break either the declarative semantics
or programmer expectations,
but it does have the downside of breaking existing code
that calls that predicate in that mode.
\end{itemize}

We chose the third approach as the best one available.
We deleted the reverse (\co{out},\co{out},\co{in}) mode
of string \sym{append/3},
and created \sym{nondet\_append/3},
a new predicate in the string module,
to replace it.
This new predicate has only one mode,
the (\co{out},\co{out},\co{in}) mode,
and it splits its input string between code points
(provided the input string is itself well-formed).
This does break backward compatibility, but it does so visibly:
any old code that calls string \sym{append/3}
in its now-deleted mode it would get a compiler error,
until the call site is updated to call \sym{nondet\_append/3} instead.


\section{Partial correctness}
\label{sec:partial-correctness}

Clauses are supposed to state things that are
true in the intended interpretation.
For example,
in Figure~\ref{fig:len-app}
the first clause of \sym{len/1} states that
the length of the empty list is zero.
The second states that,
no matter what terms we substitute
for the variables \co{\_} and \co{Xs},
the length of \co{[\_~|~Xs]} will be one greater than
the length of \co{Xs}---%
in other words the length of a non-empty list
is one greater than the length of its tail.
Both statements are true
according to our intended interpretation.

Furthermore,
the clauses cover every possible list,
in the sense that every list is either empty or non-empty,
and every non-empty list has a tail that is also a list.
Perhaps surprisingly,
this is enough to conclude that our implementation is correct,
at least as far as arguments and return values are concerned.

Our argument here depends on two points,
which may be regarded as two sides of the same coin:
\begin{itemize}
\item
Each of the clauses defining the function is a valid statement,
where by valid we mean that every instance of the clause
is true in the intended interpretation.
This ensures that there are no ``wrong answers\label{gi:wrong-answer}'':
ground atoms that are intended to be false,
but are true according to the program as written.
We refer to this condition as
\emph{clause soundness\label{gi:clause-soundness}}.
\item
Between them,
the clauses cover every possible ground atom
that is true in the intended interpretation.
This ensures that there are no ``missing answers\label{gi:missing-answer}'':
ground atoms that are intended to be true,
but are false according to the program as written.
We refer to this condition as
\emph{clause completeness\label{gi:clause-completeness}}.
\end{itemize}
The two classes of bugs being avoided here,
wrong answers and missing answers,
are the bugs that are observable in
the (classical) declarative semantics.

It is worth noting that, in many cases,
Mercury's mode and determinism systems can
make the compiler check the coverage for us:
if the determinism indicates that calls cannot fail
(that is, if the determinism is
\co{det}, \co{multi}, or \co{cc\_multi}),
then all possible values of the type must be covered
for any argument with mode \co{in}.
In the case of the \sym{len/1} function,
the one argument is an input
because this is the default mode for functions,
and this mode of the function is \co{det}
because this is the default determinism
for functions in their default mode.
Had we not covered every possible list,
the compiler would have issued a determinism error,
so we can safely assume that
the definition covers all possible solutions.
The same also applies to any other function declared with
the default mode.

Continuing with the examples,
the first clause of \sym{app/3} is a fact, which states that
if you append the empty list and any other list,
the result will be the same as the other list.
The second clause is a rule;
these are taken as logical implications
in which the body implies the head
(that is, \co{:-} is interpreted as $\leftarrow$).
So this clause is stating that, for any variable assignment,
if \co{Cs} is the result of appending \co{As} and \co{Bs},
then \co{[X | Cs]} is the result of
appending \co{[X | As]} and \co{Bs}.
Again, both clauses are valid according to the intended interpretation,
and the definition is clause complete.
In this case clause completeness means that,
for every atom that is intended to be true,
there is either a fact that covers it,
or a rule whose head covers it and
whose body is intended to be true
(under the same variable assignment).

Since both conditions are satisfied,
we can conclude in a similar way to \sym{len/1}
that our implementation of \sym{app/3} is correct.

We have been saying ``correct'' here,
but this is only as far as the arguments
(and return values, if present)
are concerned,
which is to say that there are neither wrong nor missing answers.
Other kinds of bugs,
such as \mbox{unintended} exceptions or nontermination,
poor computational complexity,
or unbounded stack usage,
are not observable in the declarative semantics.
We therefore refer to correctness in the above sense
as \emph{partial correctness\label{gi:partial-correctness}}.
This is akin to type correctness,
in the sense that it rules out a certain class of bugs,
but cannot rule out all bugs.

The results of this section can be summarized with a theorem.

\begin{theorem}[Partial correctness] \label{thm:partial-correctness}
If every clause in a program is true in the intended interpretation
and every predicate and function definition is clause complete
according to this interpretation,
then the program is partially correct.
\end{theorem}

\noindent
A corollary of this is that if a program is not partially correct,
that is, if it produces wrong answers
or misses answers that it should have produced,
then there is at either least one clause in the program
with an instance that is not true in the intended interpretation,
or at least one definition that is not clause complete.


\section{Running example: queue implementation}
\label{sec:queue-impl}

Armed with the notion of partial correctness,
we are in a position to attempt
an implementation of the queue ADT,
and make a judgement as to
whether it implements the intended interpretation.

We first need to choose an implementation for the \sym{queue/1} type.
One technique is to use a pair of lists
representing the front portion and the back portion of a queue.
The queue is split at an arbitrary point
so the two portions can be any length, including zero,
and the back portion is stored in reverse order.
In this way,
the head of each list corresponds to
one end of the queue or the other,
which are the positions in the queue
that our interface allows access to.

The type can be defined as follows:
\begin{verbatim}
    :- type queue(T)
        --->    q(
                    back  :: list(T),
                    front :: list(T)
                ).
\end{verbatim}
We have placed the reversed back list as the first argument,
as a reminder that it is in fact back-to-front.
% XXX I wouldn't consider that to be a useful reminder.
% XXX I would consider naming it "rev_back" to be a useful reminder.

% XXX I would prefer naming the data constructor "queue".

To formalize the above description,
we can give the intended interpretation of the \sym{q/2}
data constructor.
Although it is just a symbol
and not a function in the computational sense,
it still has an intended interpretation,
and we can describe it as follows:
\[
    \ct{q}([y_1, \ldots, y_m], [x_1, \ldots, x_n]) =
        [x_1, \ldots, x_n, y_m, \ldots, y_1]
\]
This just says exectly what we said above.
% XXX This shows that putting "rev_back" before "front" is counter-intuitive.
% XXX Using b and f (for back and front) would be better than x and y.

We can first give a definition for the \sym{list/1} function,
which is intended to be the identity function
on the interpretation of its argument,
but needs to convert between the two representations
of a finite sequence.
The single clause is:
\begin{verbatim}
    list(q(Y, X)) = append(X, reverse(Y)).
\end{verbatim}
% XXX We should use Front and Back.
% XXX In general, we should encourage the use of one-character variable names.
This code uses
the \sym{append/2} and \sym{reverse/1} functions
that are defined in the list module of the standard library.

It is instructive to look at how
the clause as a whole is interpreted.
Since \co{X} and \co{Y} are lists,
and we have given the interpretations of the other symbols,
plugging things in results in the following
for each side of the equation:
\begin{IEEEeqnarray*}{rCl}
\IEEEeqnarraymulticol{3}{l}{
    \ct{list}(\ct{q}([y_1, \ldots, y_m], [x_1, \ldots, x_n])
} \\ \quad
    & = & \ct{list}([x_1, \ldots, x_n, y_m, \ldots, y_1]) \\
    & = & [x_1, \ldots, x_n, y_m, \ldots, y_1] \\
\IEEEeqnarraymulticol{3}{l}{
    \ct{append}([x_1, \ldots, x_n], \ct{reverse}([y_1, \ldots, y_m]))
} \\ \quad
    & = & \ct{append}([x_1, \ldots, x_n], [y_m, \ldots, y_1]) \\
    & = & [x_1, \ldots, x_n, y_m, \ldots, y_1]
\end{IEEEeqnarray*}
Both sides are interpreted equally,
so we can say that this clause is sound.
Since this a function with the default mode,
the clause completeness condition is checked for us,
and thus we can conclude that
our implementation of \sym{list/1} is partially correct.

A simple version of \sym{eq/2}
can be defined by converting both queues to lists:
\begin{verbatim}
    eq(Q1, Q2) :- list(Q1) = list(Q2).
\end{verbatim}
The clause soundness condition can easily be verified,
since the symbols all denote identities.
The clause completeness condition holds
because the calls to \sym{list/1} cover every possible queue.

Implementing \sym{init/0} is also simple,
as the empty queue must have both the front and back lists empty:
\begin{verbatim}
    init = q([], []).
\end{verbatim}
We can define the four main operations as follows:
\begin{verbatim}
    put(Z, q(Y, X), q([Z | Y], X)).
    get(Z, q(Y, [Z | X]), q(Y, X)).
    unput(Z, q([Z | Y], X), q(Y, X)).
    unget(Z, q(Y, X), q(Y, [Z | X])).
\end{verbatim}
% XXX Again, using B and F (for back and front) would be better than X and Y.
As before,
by plugging in our interpretations
we can make judgements about correctness.
Doing so,
and then renaming lists of mixed $x$s and $y$s to lists of $t$s for clarity,
we get Figure~\ref{fig:queue-ops},
which shows that our clauses match their intended interpretations exactly,
which means the clause soundness condition is satisfied.
% XXX We should put each clause just before its equation,
% to prevent the need for page flipping,
% but I don't see how this can be done within a single IEEEeqnarray.
\begin{figure}[htb]
\begin{verbatim}
    put(Z, q(Y, X), q([Z | Y], X)).
\end{verbatim}
\begin{IEEEeqnarray*}{rCl}
    \IEEEeqnarraymulticol{3}{l}{
        \ct{put}(z, \ct{q}([y_1, \ldots, y_m], [x_1, \ldots, x_n]),
            \ct{q}([z, y_1, \ldots, y_m], [x_1, \ldots, x_n]))
    } \\ \quad
    & \Leftrightarrow &
        \ct{put}(z, [x_1, \ldots, x_n, y_m, \ldots, y_1],
            [x_1, \ldots, x_n, y_m, \ldots, y_1, z]) \\
    & \Leftrightarrow &
        \ct{put}(z, [t_1, \ldots, t_{m+n}], [t_1, \ldots, t_{m+n}, z])
\end{IEEEeqnarray*}
\begin{verbatim}
    get(Z, q(Y, [Z | X]), q(Y, X)).
\end{verbatim}
\begin{IEEEeqnarray*}{rCl}
    \IEEEeqnarraymulticol{3}{l}{
        \ct{get}(z, \ct{q}([y_1, \ldots, y_m], [z, x_1, \ldots, x_n]),
            \ct{q}([y_1, \ldots, y_m], [x_1, \ldots, x_n]))
    } \\
    & \Leftrightarrow &
        \ct{get}(z, [z, x_1, \ldots, x_n, y_m, \ldots, y_1],
            [x_1, \ldots, x_n, y_m, \ldots, y_1]) \\
    & \Leftrightarrow &
        \ct{get}(z, [z, t_1, \ldots, t_{m+n}], [t_1, \ldots, t_{m+n}])
\end{IEEEeqnarray*}
\begin{verbatim}
    unput(Z, q([Z | Y], X), q(Y, X)).
\end{verbatim}
\begin{IEEEeqnarray*}{rCl}
    \IEEEeqnarraymulticol{3}{l}{
        \ct{unput}(z, \ct{q}([z, y_1, \ldots, y_m], [x_1, \ldots, x_n]),
            \ct{q}([y_1, \ldots, y_m], [x_1, \ldots, x_n]))
    } \\
    & \Leftrightarrow &
        \ct{unput}(z, [x_1, \ldots, x_n, y_m, \ldots, y_1, z],
            [x_1, \ldots, x_n, y_m, \ldots, y_1]) \\
    & \Leftrightarrow &
        \ct{unput}(z, [t_1, \ldots, t_{m+n}, z], [t_1, \ldots, t_{m+n}])
\end{IEEEeqnarray*}
\begin{verbatim}
    unget(Z, q(Y, X), q(Y, [Z | X])).
\end{verbatim}
\begin{IEEEeqnarray*}{rCl}
    \IEEEeqnarraymulticol{3}{l}{
        \ct{unget}(z, \ct{q}([y_1, \ldots, y_m], [x_1, \ldots, x_n]),
            \ct{q}([y_1, \ldots, y_m], [z, x_1, \ldots, x_n]))
    } \\
    & \Leftrightarrow &
        \ct{unget}(z, [x_1, \ldots, x_n, y_m, \ldots, y_1],
            [z, x_1, \ldots, x_n, y_m, \ldots, y_1]) \\
    & \Leftrightarrow &
        \ct{unget}(z, [t_1, \ldots, t_{m+n}], [z, t_1, \ldots, t_{m+n}])
\end{IEEEeqnarray*}
\caption{Code and semantics of initial versions of queue operations.
\label{fig:queue-ops}}
\end{figure}

At this point we could compile the above predicates successfully.
If we run a test program, however,
calls to the \co{semidet} predicates
will sometimes fail when there is supposed to be a solution.
For example,
putting an element in an empty queue
and then trying to get it out again
does not produce the element.
The program has a missing answer bug!

The problem is that we have only checked
the clause soundness condition,
and not the clause completeness condition.
For the \co{det} predicates \sym{put/3} and \sym{unget/3},
the compiler checks this latter condition for us,
but for the \co{semidet} predicates \sym{get/3} and \sym{unput/3},
we need to make sure that
all possible values of the second argument---%
which is the input argument of both predicates---%
are handled.

The second argument in the above clause for \sym{get/3}
is \co{q(Y, [Z | X])},
which only covers cases where the front list is not empty.
% XXX The "front" list is the second argument, which again is contra-intuitive.
We need to determine what should happen if the front list is empty.

Consider the following equivalence:
\[
    \ct{q}(y, []) = \ct{q}([], \ct{reverse}(y))
\]
This can easily be seen to be true
by plugging in the interpretation of the various symbols.
If, for the empty list case,
we replace the left hand side of this equation with the right hand side
\emph{before} getting the element from the front of the list,
the call will not fail,
unless the entire queue is empty,
in which case failure is the expected result.
The code that performs this is as follows:
\begin{verbatim}
    get(Z, q(Y, []), q([], X)) :-
        [Z | X] = reverse(Y).
\end{verbatim}
To check the result,
we can once again plug in the interpretations.
The clause body gives us:
\begin{IEEEeqnarray*}{rCl}
    \IEEEeqnarraymulticol{3}{l}{
        [z, x_1, \ldots, x_n] = \ct{reverse}([y_1, \ldots, y_m])
    } \\ \quad
    & \Leftrightarrow &
        [z, x_1, \ldots, x_n] = [y_m, \ldots, y_1] \\
    & \Leftrightarrow &
        z = y_m \land [x_1, \ldots, x_n] = [y_{m-1}, \ldots, y_1]
\end{IEEEeqnarray*}
This is saying that the body is only true
when these last equations hold.
For the clause head we get:
\begin{IEEEeqnarray*}{rCl}
    \IEEEeqnarraymulticol{3}{l}{
        \ct{get}(z, \ct{q}([y_1, \ldots, y_m], []),
            \ct{q}([], [x_1, \ldots, x_n]))
    } \\ \quad
    & \Leftrightarrow &
        \ct{get}(z, [y_m, \ldots, y_1], [x_1, \ldots, x_n])
\end{IEEEeqnarray*}
If we use the equations derived from the clause body
to substitute variables in the above,
and then rename some variables,
we end up with:
\begin{IEEEeqnarray*}{rCl}
    \quad & \Leftrightarrow &
        \ct{get}(z, [z, x_1, \ldots, x_n], [x_1, \ldots, x_n])
        \hspace{1.4em} \\
    & \Leftrightarrow &
        \ct{get}(z, [z, t_1, \ldots, t_n], [t_1, \ldots, t_n])
\end{IEEEeqnarray*}
This matches the intended interpretation, as required,
and as the two clauses together now cover all possible solutions,
we can conclude that the implementation is correct.

An extra clause for \sym{unput/3} can be derived in a similar way
to the extra clause for \sym{get/3},
except that here it is the front list that is reversed and put at the back:
\begin{verbatim}
    unput(Z, q([], X), q(Y, [])) :-
        [Z | Y] = reverse(X).
\end{verbatim}
Verifying the correctness of \sym{unput/3}
is left as an exercise for the reader.


\section{Declarative debugging}
\label{sec:decl-debug}

Declarative debugging is a debugging technique
in which the debugger compares the actual solutions of calls
(obtained by running the program)
with their intended solutions in the declarative semantics
(obtained by asking the programmer).

The process of debugging, broadly speaking,
can be broken down into the following three phases.
\begin{enumerate}
\item
Observe a bug symptom.
In the classical semantics,
the two types of symptoms that the programmer can observe
are wrong answers and missing answers.
\item
Localize the bug.
The programmer narrows the problem down to a part of the source,
preferably small,
that is able to explain at least some of the incorrect behaviour.
\item
Fix the bug.
The programmer reasons about the code,
in order to try to determine how to make it correct.
\end{enumerate}
Declarative debugging applies to the second phase.
The technique is an algorithm,
which may be followed manually by the programmer
or may be automated by a debugging tool,
that is able to narrow the immediate source of a bug
down to a single predicate or function.
Theorem~\ref{thm:partial-correctness} implies that this is possible.

\begin{figure}[htb]
\begin{verbatim}
    :- type digits == list(int).

    :- func to_string(integer) = string.
    to_string([]) = "0".
    to_string(As @ [_ | _]) =
        append_list(map(string, reverse(As))).

    :- func add(digits, digits) = digits.
    add([], Bs) = Bs.
    add(As @ [_ | _], []) = As.
    add([A | As], [B | Bs]) = [A + B | add(As, Bs)].
\end{verbatim}
\caption{
A buggy implementation of \co{digits},
which represent arbitrary precision integers.
\label{fig:buggy-ints}}
\end{figure}

Consider the snippet of (buggy) code in Figure~\ref{fig:buggy-ints},
that represents arbitrary precision integers
as lists of decimal digits
starting from the least significant.
(This means that e.g.\: the list \co{[5,1]} represents the integer 15.)
It provides a function
to convert an integer to a string,
and a function to add two integers.

If we call $\ct{to\_string}(\ct{add}([2],[5,1]))$
the answer ``17'' is returned,
which is the answer that we intended (since 2 + 15 = 17).
If we call $\ct{to\_string}(\ct{add}([6],[7]))$
it returns ``13'',
which is also the answer that we intended (since 6 + 7 = 13).
In this case there were incorrect intermediate values,
but we did not observe this in the result
so we are not in a position to commence debugging.

If we call $\ct{to\_string}(\ct{add}([2,6,1],[3,7]))$
then we intend it to return ``235'' (since 162 + 73 = 235),
but instead it returns ``1135'',
which is a wrong answer.
Thus we have observed a bug symptom.

To localize this bug we start at the bug symptom,
which for us is the atom that was incorrect:
\begin{verbatim}
    to_string(add([2,6,1], [3,7])) = "1135"
\end{verbatim}
We can first check the call to \sym{add/2}.
In this case the following atom appears:
\begin{verbatim}
    add([2,6,1], [3,7]) = [5,13,1]
\end{verbatim}
This is false in the intended interpretation,
because integers are supposed to be represented
by a list whose elements are all in the range 0 to 9,
and 13 is outside that range.
Since this is a wrong answer, we proceed to debug the atom.
It matches the third clause of \sym{add/2},
the instance of which contains the following calls:
\begin{verbatim}
    2 + 3 = 5
    add([6,1], [7]) = [13,1]
\end{verbatim}
The first is obviously true,
but the second is false because $16 + 7 = 23$,
so we intended the result to be $[3,2]$.
Again, the third clause is matched and the calls made are:
\begin{verbatim}
    6 + 7 = 13
    add([1], []) = [1]
\end{verbatim}
In this case \emph{both} atoms are true in the intended interpretation.
Since this instance of the third clause of \sym{add/2}
takes the results of these calls, all of which are correct,
and constructs an incorrect result from them,
we can conclude that the third clause contains a bug,
And indeed it does,
since it does not allow for a carry bit
to flow over to the next digit.

Figure~\ref{fig:dd-session} shows
the transcript of an \co{mdb} session,
that uses the declarative debugger to find this problem.
The process looks a bit different to how we just described it,
but that is because the debugger assumes
that builtin functions such as \co{+} are correct,
which means that it does not ask questions about their correctness.

\begin{figure}[hb]
\begin{verbatim}
    Melbourne Mercury Debugger, mdb version DEV.
    Copyright 1998-2012 The University of Melbourne.
    Copyright 2013-2023 The Mercury team.
    mdb is free software; there is absolutely no warranty...
           1:      1  1 CALL pred arbint.main/2-0 (det)
    mdb>
           2:      2  2 CALL func arbint.add/2-0 (det)
    mdb> f
          17:      2  2 EXIT func arbint.add/2-0 (det)
    mdb> dd
    add([2, 6, 1], [3, 7]) = [5, 13, 1]
    Valid? n
    add([6, 1], [7]) = [13, 1]
    Valid? n
    add([1], []) = [1]
    Valid? y
    Found incorrect contour:
    +(6, 7) = 13
    add([1], []) = [1]
    add([6, 1], [7]) = [13, 1]
    Is this a bug? y
          16:      4  3 EXIT func arbint.add/2-0 (det)
    mdb> quit -y
\end{verbatim}
\caption{
An \co{mdb} declarative debugging session.
\label{fig:dd-session}}
\end{figure}

Note \co{mdb} uses ``contour'' to mean
``a path execution takes through the body of a clause''.
In cases like this where the clause is a simple conjunction,
this means all the goals in the clause,
but in clauses containing if-then-else or disjunctions,
it would mean just the goals along the path execution took
inside those constructs to compute the wrong answer being debugged.

\label{end:decl-debug}

Bug fixing,
the third phase of debugging,
might start with defining a function \sym{add\_with\_carry/3},
where the intended interpretation is:
\[
    \text{for }a, b \in [0..9],\ c \in \{0, 1\},
        \ct{add\_with\_carry}(a, b, c) = a + b + c
\]
Then \sym{add/2} could be implemented as:
\begin{verbatim}
    add(As, Bs) = add_with_carry(As, Bs, 0).
\end{verbatim}
Implementing \sym{add\_with\_carry/3}
is left as an exercise for the reader.


\section{Summary}

Interpretations of function and predicate symbols
provide us with a meaning for our programs.
Herbrand interpretations give the meaning
from the compiler's point of view,
in purely syntactic terms.
More generally, interpretations describe,
sometimes informally,
the behaviour of the functions and predicates in a program
with regard to its inputs and outputs.

The interpretation of multi-moded predicates
greatly helps in clarifying how different modes should behave.
This is particularly important when considering
predicates and functions that use mode-dependent clauses
(such as the predicate \sym{append/3}
in the string module of the standard library)
whose consistency the compiler cannot verify in the general case.

One interpretation in particular
is called the intended interpretation.
This acts as a specification
that reflects what the programmer intends to implement.
With it, we can determine the partial correctness of a program
with respect to wrong answer and missing answer bugs.

In particular,
it is expressive enough to allow us to determine
whether an individual clause is sound,
and whether a definition is complete.
Thus, it can assist with bug localization and fixing,
as well as help with avoiding bugs in the first place.
We have given some simple examples to illustrate this,
as well as introducing a queue ADT
which we use as a running example.

In the remainder of this guide
we take a more formal look at
how Mercury's semantics is defined,
as well as some additional topics of interest.
